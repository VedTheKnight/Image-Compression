{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import dct, idct\n",
    "import bitstring\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "import heapq\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPEG Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JPEG:\n",
    "    def __init__(self, Q = 50):\n",
    "        self.Q = Q\n",
    "        self.quantization_matrix = np.array([   [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "                                                [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                                                [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                                                [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                                                [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                                                [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                                                [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                                                [72, 92, 95, 98, 112, 100, 103, 99],])\n",
    "        self.scaled_quantization_matrix = np.round(self.quantization_matrix * (50.0/Q))\n",
    "    \n",
    "    # define the dct and idct functions for the blocks\n",
    "    def _dct2(self, block):\n",
    "        dct_val = dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
    "        return dct_val\n",
    "\n",
    "    def _idct2(self, block):\n",
    "        return idct(idct(block.T, norm='ortho').T, norm='ortho')\n",
    "    \n",
    "    # Runs quantization while compression\n",
    "    def _quantize(self, block):\n",
    "        return np.round(block / self.scaled_quantization_matrix)\n",
    "\n",
    "    # Runs dequantization while decompression\n",
    "    def _dequantize(self, block):\n",
    "        return block * self.scaled_quantization_matrix\n",
    "    \n",
    "    # breaks the image into 8x8 patches\n",
    "    def _chunkify(self, image):\n",
    "        chunks = []\n",
    "        h,w = np.shape(image)\n",
    "        for i in range(0, h, 8):\n",
    "            for j in range(0, w, 8):\n",
    "                chunk = image[i:i+8, j:j+8]\n",
    "                chunks.append(chunk)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    # recombines the patches into the original image size\n",
    "    def _dechunkify(self, chunks, original_shape):\n",
    "        h, w = original_shape\n",
    "        image = np.zeros((h, w), dtype=chunks[0].dtype)  # Create an empty array with the original shape\n",
    "        chunk_idx = 0  # Index to keep track of the current chunk\n",
    "\n",
    "        for i in range(0, h, 8):\n",
    "            for j in range(0, w, 8):\n",
    "                # Place the current chunk into the corresponding position in the image\n",
    "                image[i:i+8, j:j+8] = chunks[chunk_idx]\n",
    "                chunk_idx += 1\n",
    "\n",
    "        return image\n",
    "\n",
    "    # flattens the matrix into its zig-zag traversal\n",
    "    def _zigzag(self, matrix):\n",
    "        rows, cols = matrix.shape\n",
    "        result = []\n",
    "\n",
    "        for s in range(rows + cols - 1):\n",
    "            if s % 2 == 0:  # Even diagonals (move up-right)\n",
    "                x = min(s, rows - 1)\n",
    "                y = s - x\n",
    "                while x >= 0 and y < cols:\n",
    "                    result.append(matrix[x, y])\n",
    "                    x -= 1\n",
    "                    y += 1\n",
    "            else:  # Odd diagonals (move down-left)\n",
    "                y = min(s, cols - 1)\n",
    "                x = s - y\n",
    "                while y >= 0 and x < rows:\n",
    "                    result.append(matrix[x, y])\n",
    "                    x += 1\n",
    "                    y -= 1\n",
    "\n",
    "        return np.array(result)\n",
    "\n",
    "    # converts a flattened matrix into the original form by placing the elements in a zig zag manner\n",
    "    def _reverse_zigzag(self, flattened, rows, cols):\n",
    "        # Initialize an empty 2D matrix\n",
    "        matrix = np.zeros((rows, cols), dtype=flattened.dtype)\n",
    "\n",
    "        # Fill the matrix using the reverse zig-zag order\n",
    "        index = 0\n",
    "        for s in range(rows + cols - 1):\n",
    "            if s % 2 == 0:  # Even diagonals (move up-right)\n",
    "                x = min(s, rows - 1)\n",
    "                y = s - x\n",
    "                while x >= 0 and y < cols:\n",
    "                    matrix[x, y] = flattened[index]\n",
    "                    index += 1\n",
    "                    x -= 1\n",
    "                    y += 1\n",
    "            else:  # Odd diagonals (move down-left)\n",
    "                y = min(s, cols - 1)\n",
    "                x = s - y\n",
    "                while y >= 0 and x < rows:\n",
    "                    matrix[x, y] = flattened[index]\n",
    "                    index += 1\n",
    "                    x += 1\n",
    "                    y -= 1\n",
    "\n",
    "        return matrix\n",
    "    \n",
    "    # Helper functions for huffman encoding and RLE\n",
    "    def _build_huffman_tree(self, frequencies):\n",
    "        # Create a priority queue (min-heap) to build the Huffman tree\n",
    "        heap = [[weight, [symbol, \"\"]] for symbol, weight in frequencies.items()]\n",
    "        heapq.heapify(heap)\n",
    "        \n",
    "        while len(heap) > 1:\n",
    "            low = heapq.heappop(heap)\n",
    "            high = heapq.heappop(heap)\n",
    "            for pair in low[1:]:\n",
    "                pair[1] = '0' + pair[1]\n",
    "            for pair in high[1:]:\n",
    "                pair[1] = '1' + pair[1]\n",
    "            heapq.heappush(heap, [low[0] + high[0]] + low[1:] + high[1:])\n",
    "        \n",
    "        # Generate the Huffman codes\n",
    "        huffman_codes = {}\n",
    "        for symbol, code in heap[0][1:]:\n",
    "            huffman_codes[symbol] = code\n",
    "        return huffman_codes\n",
    "\n",
    "    def _run_length_encoding(self, matrix):\n",
    "        rle = []\n",
    "        zero_count = 0\n",
    "        \n",
    "        for value in matrix:\n",
    "            if value == 0:\n",
    "                zero_count += 1  # Increment zero counter\n",
    "                if zero_count == 16:\n",
    "                    rle.append((15, 0))\n",
    "                    zero_count = 0\n",
    "            else:\n",
    "                rle.append((zero_count, value))  # Store the number of zeros before the value\n",
    "                zero_count = 0  # Reset zero counter after encountering a non-zero value\n",
    "        \n",
    "        return rle\n",
    "\n",
    "    def _huffman_encoding(self, values):\n",
    "        frequencies = defaultdict(int)\n",
    "        for val in values:\n",
    "            frequencies[val] += 1\n",
    "        \n",
    "        huffman_codes = self._build_huffman_tree(frequencies)\n",
    "        return huffman_codes\n",
    "\n",
    "    # Function to encode the image post scaling dct and quantization into rle and huffman and store into a bin file\n",
    "    def _encode(self, flattened_matrices, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            rle_result = []\n",
    "\n",
    "            for i in range(0,len(flattened_matrices)):\n",
    "                rle = self._run_length_encoding(flattened_matrices[i])\n",
    "                rle_result.extend(rle)\n",
    "                rle_result.append((0,0))\n",
    "\n",
    "            values = [value for count, value in rle_result]  # Only values for Huffman encoding\n",
    "            huffman_codes = self._huffman_encoding(values)    \n",
    "\n",
    "            # Store the Quality Factor in the file \n",
    "            f.write(np.array([self.Q], dtype=np.uint8).tobytes()) \n",
    "            f.flush()\n",
    "        \n",
    "\n",
    "            # Store the Huffman table in the file (value -> huffman code mapping)\n",
    "            f.write(np.array([len(huffman_codes)], dtype=np.uint16).tobytes())  # Write the number of unique values in Huffman table\n",
    "            f.flush()            \n",
    " \n",
    "\n",
    "            # Collect all Huffman codes\n",
    "            all_huffman_codes = []\n",
    "\n",
    "            for value, code in huffman_codes.items():\n",
    "                f.write(np.array([value], dtype=np.int16).tobytes())  \n",
    "                f.flush()\n",
    "                size_in_bits = len(code)\n",
    "                f.write(np.array([size_in_bits], dtype=np.uint8).tobytes())  # Write the size of the Huffman code\n",
    "                f.flush()\n",
    "                all_huffman_codes.append(code)\n",
    "\n",
    "            all_huffman_codes_str = ''.join(all_huffman_codes)\n",
    "            total_size_in_bits = len(all_huffman_codes_str)\n",
    "\n",
    "            f.write(np.array([total_size_in_bits], dtype=np.uint32).tobytes())\n",
    "            f.flush()\n",
    "\n",
    "            padding_length = 0\n",
    "            if len(all_huffman_codes_str) % 8 != 0:\n",
    "                padding_length = 8 - (len(all_huffman_codes_str) % 8)\n",
    "            all_huffman_codes_str = all_huffman_codes_str + '0' * padding_length\n",
    "\n",
    "            bitstream = bitstring.BitStream(bin=all_huffman_codes_str)\n",
    "            f.write(bitstream.bytes)  # Write the Huffman code as bytes\n",
    "            f.flush()\n",
    "\n",
    "            # To store the RLE Result\n",
    "            # Store the size of the rle_result\n",
    "            f.write(np.array([len(rle_result)], dtype=np.uint32).tobytes())  \n",
    "            f.flush()            \n",
    "\n",
    "            all_huffman_codes = []\n",
    "            all_huffman_codes_str = ''\n",
    "\n",
    "            for count, value in rle_result:\n",
    "                huffman_code = huffman_codes[value]  # Find Huffman code for this value\n",
    "                size_in_bits = len(huffman_code)  # The size in bits of the Huffman code\n",
    "\n",
    "                f.write(np.array([count], dtype=np.uint8).tobytes())\n",
    "                f.write(np.array([size_in_bits], dtype=np.uint8).tobytes())\n",
    "\n",
    "                f.flush()\n",
    "\n",
    "                all_huffman_codes.append(huffman_code)\n",
    "\n",
    "            all_huffman_codes_str = ''.join(all_huffman_codes)\n",
    "            total_size_in_bits = len(all_huffman_codes_str)\n",
    "\n",
    "            # Calculate padding to ensure byte alignment\n",
    "            if total_size_in_bits % 8 != 0:\n",
    "                padding_length = 8 - (total_size_in_bits % 8)\n",
    "                all_huffman_codes_str += '0' * padding_length  # Add padding to the bitstream\n",
    "            else:\n",
    "                padding_length = 0\n",
    "\n",
    "            # Write the total size in bits to the file (before padding)\n",
    "            f.write(np.array([total_size_in_bits], dtype=np.uint32).tobytes())\n",
    "            f.flush()\n",
    "\n",
    "            # Convert the padded bitstream into a byte array\n",
    "            bitstream = bitstring.BitStream(bin=all_huffman_codes_str)\n",
    "            f.write(bitstream.bytes)  # Write the Huffman codes as bytes\n",
    "            f.flush()\n",
    "\n",
    "\n",
    "\n",
    "    # Finds the original value given the huffman code and the huffman table\n",
    "    def _decode_huffman_code(self, code_bits, huffman_codes):\n",
    "        # Reverse the Huffman coding to find the value for the given code bits\n",
    "        for value, huffman_code in huffman_codes.items():\n",
    "            if code_bits == huffman_code:\n",
    "                return value\n",
    "        raise ValueError(f\"Unknown Huffman code: {code_bits}\")\n",
    "\n",
    "    # takes as input the original image and a quality factor Q\n",
    "    def compress(self, image, filename):\n",
    "        image = image.astype('float32') # cast to float\n",
    "        image = image - 128.0 # rescale the values\n",
    "        chunks = self._chunkify(image) # break into 8x8 chunks \n",
    "        \n",
    "        flattened_matrices = []\n",
    "        for chunk in chunks:\n",
    "            quantized_matrix = self._quantize(self._dct2(chunk))\n",
    "            flattened_matrix = self._zigzag(quantized_matrix)\n",
    "            flattened_matrices.append(flattened_matrix)\n",
    "\n",
    "        self._encode(flattened_matrices, filename)\n",
    "\n",
    "    def decompress(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            # Read the Quality Factor (Q)\n",
    "            Q = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "            \n",
    "            # Read the Huffman table (number of entries)\n",
    "            num_huffman_codes = np.fromfile(f, dtype=np.uint16, count=1)[0]\n",
    "\n",
    "            huffman_codes = {}\n",
    "            \n",
    "            table_entries = []\n",
    "            # Read each Huffman code (value, size)\n",
    "            for _ in range(num_huffman_codes):\n",
    "                value = np.fromfile(f, dtype=np.int16, count=1)[0]\n",
    "                size_in_bits = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                table_entries.append((value,size_in_bits))\n",
    "            \n",
    "            length_huffman_codes = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "            huffman_codes_bitstream = f.read((length_huffman_codes + 7) // 8)  # Read the total size in bytes\n",
    "            huffman_codes_bitstream = bitstring.BitStream(bytes=huffman_codes_bitstream).bin\n",
    "\n",
    "            current_pos = 0\n",
    "            for value, size_in_bits in table_entries:\n",
    "                huffman_codes[value] = huffman_codes_bitstream[current_pos:current_pos+size_in_bits]\n",
    "                current_pos+=size_in_bits\n",
    "            \n",
    "\n",
    "            # get the number of rle values\n",
    "            num_rle_values = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "\n",
    "            # 3. Decode the RLE-encoded values and sizes\n",
    "            rle_result = []\n",
    "            table_entries = []\n",
    "\n",
    "            for _ in range(num_rle_values):\n",
    "                count = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                size_in_bits = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                table_entries.append((count, size_in_bits))\n",
    "            \n",
    "            # print(table_entries)\n",
    "            \n",
    "            length_huffman_codes = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "            huffman_codes_bitstream = f.read((length_huffman_codes + 7) // 8)  # Read the total size in bytes\n",
    "            huffman_codes_bitstream = bitstring.BitStream(bytes=huffman_codes_bitstream).bin\n",
    "\n",
    "            current_pos = 0\n",
    "            for count, size_in_bits in table_entries:\n",
    "                value = self._decode_huffman_code(huffman_codes_bitstream[current_pos:current_pos+size_in_bits], huffman_codes)\n",
    "                rle_result.append((count, value))\n",
    "                current_pos+=size_in_bits\n",
    "\n",
    "\n",
    "            # Reconstruct the original flattened matrices from RLE\n",
    "            flattened_matrices = []\n",
    "            \n",
    "            current_patch = []\n",
    "            for count, value in rle_result:\n",
    "                if count == 0 and value == 0:\n",
    "                    current_patch = current_patch + [0]*(64 - len(current_patch))\n",
    "                    flattened_matrices.append(np.array(current_patch))\n",
    "                    current_patch = []\n",
    "                else:\n",
    "                    current_patch = current_patch + [0]*count + [value]\n",
    "\n",
    "\n",
    "            # convert it back to the original patch dimensions\n",
    "            for i in range(len(flattened_matrices)):\n",
    "                \n",
    "                flattened_matrices[i] = self._reverse_zigzag(flattened_matrices[i], 8, 8)\n",
    "\n",
    "                # now de-quantize the matrix and rescale\n",
    "                flattened_matrices[i] = (flattened_matrices[i] * self.scaled_quantization_matrix) \n",
    "                flattened_matrices[i] = self._idct2(flattened_matrices[i]) + 128\n",
    "            \n",
    "            # combine the patches together\n",
    "            restored_image = self._dechunkify(flattened_matrices, (8*int(np.sqrt(len(flattened_matrices))), 8*int(np.sqrt(len(flattened_matrices)))))\n",
    "            return restored_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('data/image1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "jpeg = JPEG(Q=100)\n",
    "jpeg.compress(image, \"test\")\n",
    "\n",
    "# Example usage:\n",
    "filename = \"test\"\n",
    "restored_image = jpeg.decompress(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(restored_image, cmap='gray')  # Use grayscale colormap\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful Functions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(original_image, decompressed_image):\n",
    "    # Flatten the images to 1D arrays for easier comparison\n",
    "    original_image = original_image.astype(np.float64)\n",
    "    decompressed_image = decompressed_image.astype(np.float64)\n",
    "\n",
    "    # Compute the squared differences\n",
    "    squared_diff = (original_image - decompressed_image) ** 2\n",
    "\n",
    "    # Calculate the mean squared error (MSE)\n",
    "    mse = np.mean(squared_diff)\n",
    "\n",
    "    # RMSE is the square root of MSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "def calculate_bpp(compressed_image_path, image_shape):\n",
    "    # Get the compressed file size in bits (1 byte = 8 bits)\n",
    "    file_size_in_bits = os.path.getsize(compressed_image_path) * 8\n",
    "\n",
    "    # Calculate the total number of pixels in the image\n",
    "    num_pixels = image_shape[0] * image_shape[1]\n",
    "\n",
    "    # Compute BPP\n",
    "    bpp = file_size_in_bits / num_pixels\n",
    "\n",
    "    return bpp\n",
    "\n",
    "def psnr(original, compressed):\n",
    "    original_image = original_image.astype(np.float64)\n",
    "    decompressed_image = decompressed_image.astype(np.float64)\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100  # If MSE is zero, PSNR is infinite (no difference).\n",
    "    max_pixel = 255.0\n",
    "    psnr_value = 10 * np.log10((max_pixel ** 2) / mse)\n",
    "    return psnr_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE vs BPP Plots For a Random Set of 20 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming calculate_rmse and calculate_bpp functions are defined elsewhere\n",
    "\n",
    "# Parameters\n",
    "quality_factors = range(10, 101, 5)  # Quality factors from 10 to 100 in steps of 10\n",
    "images_directory = \"data/\"  # Directory with at least 20 images\n",
    "output_directory = \"compressed_data/\"  # Directory to save compressed images\n",
    "graphs_directory = \"graphs/\"\n",
    "compressed_images_directory = \"compressed_images/\"\n",
    "\n",
    "# Process images\n",
    "image_files = [os.path.join(images_directory, f) for f in os.listdir(images_directory)]\n",
    "image_files = image_files  # Use at least 25 images\n",
    "\n",
    "# Initialize lists for the all-in-one graph\n",
    "all_rmse_values = []\n",
    "all_bpp_values = []\n",
    "image_labels = []\n",
    "\n",
    "# Loop through each image and process\n",
    "for image_path in image_files:\n",
    "    rmse_values = []\n",
    "    bpp_values = []\n",
    "    for q in quality_factors:\n",
    "        \n",
    "        jpeg = JPEG(Q=q)  \n",
    "        original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "        # Compress and decompress\n",
    "        compressed_path = os.path.join(output_directory, f\"compressed_q{q}_{os.path.splitext(os.path.basename(image_path))[0]}\")\n",
    "        jpeg.compress(original_image, compressed_path)  \n",
    "        decompressed_image = jpeg.decompress(compressed_path)  \n",
    "\n",
    "        decompressed_image_path = os.path.join(compressed_images_directory, f\"compressed_q{q}_{os.path.splitext(os.path.basename(image_path))[0]}.jpg\")\n",
    "\n",
    "        # Save the decompressed image as a .jpg file\n",
    "        cv2.imwrite(decompressed_image_path, decompressed_image)\n",
    "\n",
    "        if(original_image.shape != decompressed_image.shape):\n",
    "            print(\"Error in image_path \", image_path)\n",
    "            print(\"Quality Factor \", q)\n",
    "            continue\n",
    "        # Calculate RMSE and BPP\n",
    "        rmse = calculate_rmse(original_image, decompressed_image)  \n",
    "        bpp = calculate_bpp(compressed_path, original_image.shape)\n",
    "\n",
    "        rmse_values.append(rmse)\n",
    "        bpp_values.append(bpp)\n",
    "\n",
    "    # Plot individual image graph\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(bpp_values, rmse_values, marker='o', linestyle='-', label=os.path.splitext(os.path.basename(image_path))[0]) \n",
    "    plt.xlabel('Bits Per Pixel (BPP)')\n",
    "    plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "    plt.title(f'RMSE vs BPP for Image {os.path.splitext(os.path.basename(image_path))[0]}')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the individual plot\n",
    "    plot_filename = os.path.join(graphs_directory, f\"rmse_vs_bpp_{os.path.splitext(os.path.basename(image_path))[0]}.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()  # Close the figure to avoid overlapping plots\n",
    "\n",
    "    # Add to the all-in-one graph data\n",
    "    all_rmse_values.extend(rmse_values)\n",
    "    all_bpp_values.extend(bpp_values)\n",
    "    image_labels.extend([os.path.splitext(os.path.basename(image_path))[0]] * len(rmse_values))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate All-in-One Graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, image_path in enumerate(image_files):\n",
    "    # Plot all images on the same graph with different labels\n",
    "    start_idx = i * len(quality_factors)\n",
    "    end_idx = (i + 1) * len(quality_factors)\n",
    "    plt.plot(all_bpp_values[start_idx:end_idx], all_rmse_values[start_idx:end_idx], marker='o', linestyle='-', label=image_labels[start_idx])\n",
    "\n",
    "plt.xlabel('Bits Per Pixel (BPP)')\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "plt.title('RMSE vs BPP for All Images')\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Images\", bbox_to_anchor=(1.05, 1), loc='upper left')  # Display legends outside the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the all-in-one plot\n",
    "all_in_one_plot_filename = os.path.join(graphs_directory, \"rmse_vs_bpp_all_images.png\")\n",
    "plt.savefig(all_in_one_plot_filename)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression Rate vs Quality Factor for a Random Set of 20 Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "compressed_files_directory = 'compressed_data/'  # Folder containing compressed images\n",
    "original_image_directory = 'data/'  # Folder containing original images\n",
    "output_plots_directory = 'graphs/'  # Folder to save generated plots\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_plots_directory, exist_ok=True)\n",
    "\n",
    "# Define quality factors\n",
    "quality_factors = range(10, 101, 5)  # Quality factors from 10 to 100 in steps of 5\n",
    "\n",
    "# Function to calculate the size of an image in bits\n",
    "def get_image_size_in_bits(image_path):\n",
    "    # Get image size in bytes\n",
    "    size_in_bytes = os.path.getsize(image_path)\n",
    "    # Convert bytes to bits\n",
    "    return size_in_bytes * 8\n",
    "\n",
    "# Get a list of original image files\n",
    "image_files = [f for f in os.listdir(original_image_directory)]\n",
    "\n",
    "# Loop through each image and calculate compression rate\n",
    "for image_file in image_files:\n",
    "    original_image_path = os.path.join(original_image_directory, image_file)\n",
    "    original_image = plt.imread(original_image_path)\n",
    "    original_image_size_bits = original_image.shape[0] * original_image.shape[1] * 8  # Height * Width * Bits per pixel\n",
    "\n",
    "    # Store compression rates for the current image\n",
    "    compression_rates_for_image = []\n",
    "\n",
    "    # Loop through each quality factor\n",
    "    for q in quality_factors:\n",
    "        # Find the corresponding compressed file\n",
    "        compressed_file_name = f\"compressed_q{q}_{os.path.splitext(image_file)[0]}\"\n",
    "        compressed_image_path = os.path.join(compressed_files_directory, compressed_file_name)\n",
    "\n",
    "        if os.path.exists(compressed_image_path):\n",
    "            compressed_image_size_bits = get_image_size_in_bits(compressed_image_path)\n",
    "            compression_rate = original_image_size_bits / compressed_image_size_bits\n",
    "            compression_rates_for_image.append(compression_rate)\n",
    "        else:\n",
    "            print(f\"Compressed file for quality factor {q} not found for {image_file}.\")\n",
    "\n",
    "    # Plot Compression Rate vs Quality Factor for the current image\n",
    "    plt.figure(figsize=(8, 6))  # Optional: Adjust the size of the plot\n",
    "    plt.plot(quality_factors, compression_rates_for_image, marker='o', label=image_file, color='b')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Quality Factor')\n",
    "    plt.ylabel('Compression Rate')\n",
    "    plt.title(f'Compression Rate vs Quality Factor\\n{image_file}')\n",
    "    \n",
    "    # Save the plot as an image file\n",
    "    plot_file_path = os.path.join(output_plots_directory, f'compression_rate_vs_q_{os.path.splitext(image_file)[0]}.png')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(plot_file_path)  # Save the plot to the output directory\n",
    "    \n",
    "    # Close the plot to avoid overlapping plots\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved plot for {image_file} at {plot_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "compressed_files_directory = 'compressed_data/'  # Folder containing compressed images\n",
    "original_image_directory = 'data/'  # Folder containing original images\n",
    "output_plots_directory = 'graphs/'  # Folder to save generated plots\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_plots_directory, exist_ok=True)\n",
    "\n",
    "# Define quality factors\n",
    "quality_factors = range(10, 101, 5)  # Quality factors from 10 to 100 in steps of 5\n",
    "\n",
    "# Function to calculate the size of an image in bits\n",
    "def get_image_size_in_bits(image_path):\n",
    "    # Get image size in bytes\n",
    "    size_in_bytes = os.path.getsize(image_path)\n",
    "    # Convert bytes to bits\n",
    "    return size_in_bytes * 8\n",
    "\n",
    "# Get a list of original image files\n",
    "image_files = [os.path.join(images_directory, f) for f in os.listdir(images_directory)]\n",
    "\n",
    "# Initialize a plot for all images\n",
    "plt.figure(figsize=(10, 8))  # Optional: Adjust the size of the plot\n",
    "\n",
    "# Loop through each image and calculate compression rate\n",
    "for image_file in image_files:\n",
    "    original_image_path = os.path.join(original_image_directory, image_file)\n",
    "    original_image = plt.imread(original_image_path)\n",
    "    original_image_size_bits = original_image.shape[0] * original_image.shape[1] * 8  # Height * Width * Bits per pixel\n",
    "\n",
    "    # Store compression rates for the current image\n",
    "    compression_rates_for_image = []\n",
    "\n",
    "    # Loop through each quality factor\n",
    "    for q in quality_factors:\n",
    "        # Find the corresponding compressed file\n",
    "        compressed_file_name = f\"compressed_q{q}_{os.path.splitext(image_file)[0]}\"\n",
    "        compressed_image_path = os.path.join(compressed_files_directory, compressed_file_name)\n",
    "\n",
    "        if os.path.exists(compressed_image_path):\n",
    "            compressed_image_size_bits = get_image_size_in_bits(compressed_image_path)\n",
    "            compression_rate = original_image_size_bits / compressed_image_size_bits\n",
    "            compression_rates_for_image.append(compression_rate)\n",
    "        else:\n",
    "            print(f\"Compressed file for quality factor {q} not found for {image_file}.\")\n",
    "\n",
    "    # Plot Compression Rate vs Quality Factor for the current image, overlayed on the same plot\n",
    "    plt.plot(quality_factors, compression_rates_for_image, marker='o', label=image_file)\n",
    "\n",
    "# Add labels and title to the overall plot\n",
    "plt.xlabel('Quality Factor')\n",
    "plt.ylabel('Compression Rate')\n",
    "plt.title('Compression Rate vs Quality Factor for All Images')\n",
    "\n",
    "# Show a legend and grid\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plot_file_path = os.path.join(output_plots_directory, 'compression_rate_vs_q_all_images.png')\n",
    "plt.savefig(plot_file_path)  # Save the plot to the output directory\n",
    "\n",
    "# Close the plot to avoid overlapping plots\n",
    "plt.close()\n",
    "\n",
    "print(f\"Saved overlayed plot for all images at {plot_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision with JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "quality_factors = range(10, 101, 5)  # Quality factors from 10 to 100 in steps of 5\n",
    "images_directory = \"data/\"  # Directory with at least 20 images\n",
    "output_directory = \"compressed_images_bin/\"  # Directory to save compressed images\n",
    "graphs_directory = \"graphs_comparison/\"\n",
    "compressed_images_directory = \"compressed_images/\"\n",
    "\n",
    "# Process images\n",
    "image_files = [os.path.join(images_directory, f) for f in os.listdir(images_directory)]\n",
    "\n",
    "# Loop through each image and process\n",
    "for image_path in image_files:\n",
    "    rmse_values_cv2 = []\n",
    "    bpp_values_cv2 = []\n",
    "    rmse_values_custom = []\n",
    "    bpp_values_custom = []\n",
    "    compression_rate_cv2 = []\n",
    "    compression_rate_custom = []\n",
    "    \n",
    "    for q in quality_factors:\n",
    "        original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # OpenCV Compression (cv2)\n",
    "        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), q]\n",
    "        _, compressed_image_cv2 = cv2.imencode('.jpg', original_image, encode_param)\n",
    "        \n",
    "        # Save the OpenCV compressed image\n",
    "        compressed_path_cv2 = os.path.join(output_directory, f\"cv2_compressed_q{q}_{os.path.splitext(os.path.basename(image_path))[0]}.jpg\")\n",
    "        with open(compressed_path_cv2, 'wb') as f:\n",
    "            f.write(compressed_image_cv2.tobytes())\n",
    "        \n",
    "        # Decompress using OpenCV (cv2)\n",
    "        decompressed_image_cv2 = cv2.imdecode(compressed_image_cv2, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Calculate RMSE and BPP for OpenCV method\n",
    "        rmse_cv2 = calculate_rmse(original_image, decompressed_image_cv2)\n",
    "        bpp_cv2 = calculate_bpp(compressed_path_cv2, original_image.shape)\n",
    "\n",
    "        # Calculate Compression Rate for OpenCV\n",
    "        original_size_cv2 = os.path.getsize(image_path)\n",
    "        compressed_size_cv2 = os.path.getsize(compressed_path_cv2)\n",
    "        compression_rate_cv2.append(original_size_cv2 / compressed_size_cv2)\n",
    "\n",
    "        rmse_values_cv2.append(rmse_cv2)\n",
    "        bpp_values_cv2.append(bpp_cv2)\n",
    "\n",
    "        # Custom JPEG Compression (assuming custom JPEG class is defined)\n",
    "        jpeg = JPEG(Q=q)  # Assuming your custom JPEG implementation is called 'JPEG'\n",
    "        \n",
    "        compressed_path_custom = os.path.join(output_directory, f\"custom_compressed_q{q}_{os.path.splitext(os.path.basename(image_path))[0]}\")\n",
    "        jpeg.compress(original_image, compressed_path_custom)  \n",
    "        decompressed_image_custom = jpeg.decompress(compressed_path_custom)  # Decompress using custom method\n",
    "\n",
    "        decompressed_image_path_custom = os.path.join(compressed_images_directory, f\"custom_compressed_q{q}_{os.path.splitext(os.path.basename(image_path))[0]}.jpg\")\n",
    "\n",
    "        # Save the decompressed custom image as a .jpg file\n",
    "        cv2.imwrite(decompressed_image_path_custom, decompressed_image_custom)\n",
    "\n",
    "        # Check for shape mismatch\n",
    "        if original_image.shape != decompressed_image_custom.shape:\n",
    "            print(f\"Error in image_path: {image_path}, Quality Factor: {q}\")\n",
    "            continue\n",
    "\n",
    "        # Calculate RMSE and BPP for custom method\n",
    "        rmse_custom = calculate_rmse(original_image, decompressed_image_custom)\n",
    "        bpp_custom = calculate_bpp(compressed_path_custom, original_image.shape)\n",
    "\n",
    "        # Calculate Compression Rate for custom method\n",
    "        original_size_custom = os.path.getsize(image_path)\n",
    "        compressed_size_custom = os.path.getsize(compressed_path_custom)\n",
    "        compression_rate_custom.append(original_size_custom / compressed_size_custom)\n",
    "    \n",
    "        rmse_values_custom.append(rmse_custom)\n",
    "        bpp_values_custom.append(bpp_custom)\n",
    "\n",
    "    # Plot the comparison of RMSE vs BPP for both methods (OpenCV vs Custom JPEG)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(bpp_values_cv2, rmse_values_cv2, marker='o', linestyle='-', label='OpenCV JPEG', color='blue')\n",
    "    plt.plot(bpp_values_custom, rmse_values_custom, marker='x', linestyle='-', label='Custom JPEG', color='red')\n",
    "    plt.xlabel('Bits Per Pixel (BPP)')\n",
    "    plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "    plt.title(f'RMSE vs BPP for Image {os.path.splitext(os.path.basename(image_path))[0]}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the comparison plot\n",
    "    plot_filename = os.path.join(graphs_directory, f\"rmse_vs_bpp_comparison_{os.path.splitext(os.path.basename(image_path))[0]}.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()  # Close the figure to avoid overlapping plots\n",
    "\n",
    "    # Plot Compression Rate vs Quality Factor for both methods (OpenCV vs Custom JPEG)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(quality_factors, compression_rate_cv2, marker='o', linestyle='-', label='OpenCV JPEG', color='blue')\n",
    "    plt.plot(quality_factors, compression_rate_custom, marker='x', linestyle='-', label='Custom JPEG', color='red')\n",
    "    plt.xlabel('Quality Factor')\n",
    "    plt.ylabel('Compression Rate')\n",
    "    plt.title(f'Compression Rate vs Quality Factor for Image {os.path.splitext(os.path.basename(image_path))[0]}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the compression rate plot\n",
    "    rate_plot_filename = os.path.join(graphs_directory, f\"compression_rate_vs_q_{os.path.splitext(os.path.basename(image_path))[0]}.png\")\n",
    "    plt.savefig(rate_plot_filename)\n",
    "    plt.close()  # Close the figure to avoid overlapping plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation over Quantization Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JPEG_Exp:\n",
    "    def __init__(self, Q = 50, quantization_matrix = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
    "                                                [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                                                [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                                                [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                                                [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                                                [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                                                [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                                                [72, 92, 95, 98, 112, 100, 103, 99],])):\n",
    "        self.Q = Q\n",
    "        self.quantization_matrix = quantization_matrix\n",
    "        self.scaled_quantization_matrix = np.round(self.quantization_matrix * (50.0/Q))\n",
    "    \n",
    "    # define the dct and idct functions for the blocks\n",
    "    def _dct2(self, block):\n",
    "        dct_val = dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
    "        return dct_val\n",
    "\n",
    "    def _idct2(self, block):\n",
    "        return idct(idct(block.T, norm='ortho').T, norm='ortho')\n",
    "    \n",
    "    # Runs quantization while compression\n",
    "    def _quantize(self, block):\n",
    "        return np.round(block / self.scaled_quantization_matrix)\n",
    "\n",
    "    # Runs dequantization while decompression\n",
    "    def _dequantize(self, block):\n",
    "        return block * self.scaled_quantization_matrix\n",
    "    \n",
    "    # breaks the image into 8x8 patches\n",
    "    def _chunkify(self, image):\n",
    "        chunks = []\n",
    "        h,w = np.shape(image)\n",
    "        for i in range(0, h, 8):\n",
    "            for j in range(0, w, 8):\n",
    "                chunk = image[i:i+8, j:j+8]\n",
    "                chunks.append(chunk)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    # recombines the patches into the original image size\n",
    "    def _dechunkify(self, chunks, original_shape):\n",
    "        h, w = original_shape\n",
    "        image = np.zeros((h, w), dtype=chunks[0].dtype)  # Create an empty array with the original shape\n",
    "        chunk_idx = 0  # Index to keep track of the current chunk\n",
    "\n",
    "        for i in range(0, h, 8):\n",
    "            for j in range(0, w, 8):\n",
    "                # Place the current chunk into the corresponding position in the image\n",
    "                image[i:i+8, j:j+8] = chunks[chunk_idx]\n",
    "                chunk_idx += 1\n",
    "\n",
    "        return image\n",
    "\n",
    "    # flattens the matrix into its zig-zag traversal\n",
    "    def _zigzag(self, matrix):\n",
    "        rows, cols = matrix.shape\n",
    "        result = []\n",
    "\n",
    "        for s in range(rows + cols - 1):\n",
    "            if s % 2 == 0:  # Even diagonals (move up-right)\n",
    "                x = min(s, rows - 1)\n",
    "                y = s - x\n",
    "                while x >= 0 and y < cols:\n",
    "                    result.append(matrix[x, y])\n",
    "                    x -= 1\n",
    "                    y += 1\n",
    "            else:  # Odd diagonals (move down-left)\n",
    "                y = min(s, cols - 1)\n",
    "                x = s - y\n",
    "                while y >= 0 and x < rows:\n",
    "                    result.append(matrix[x, y])\n",
    "                    x += 1\n",
    "                    y -= 1\n",
    "\n",
    "        return np.array(result)\n",
    "\n",
    "    # converts a flattened matrix into the original form by placing the elements in a zig zag manner\n",
    "    def _reverse_zigzag(self, flattened, rows, cols):\n",
    "        # Initialize an empty 2D matrix\n",
    "        matrix = np.zeros((rows, cols), dtype=flattened.dtype)\n",
    "\n",
    "        # Fill the matrix using the reverse zig-zag order\n",
    "        index = 0\n",
    "        for s in range(rows + cols - 1):\n",
    "            if s % 2 == 0:  # Even diagonals (move up-right)\n",
    "                x = min(s, rows - 1)\n",
    "                y = s - x\n",
    "                while x >= 0 and y < cols:\n",
    "                    matrix[x, y] = flattened[index]\n",
    "                    index += 1\n",
    "                    x -= 1\n",
    "                    y += 1\n",
    "            else:  # Odd diagonals (move down-left)\n",
    "                y = min(s, cols - 1)\n",
    "                x = s - y\n",
    "                while y >= 0 and x < rows:\n",
    "                    matrix[x, y] = flattened[index]\n",
    "                    index += 1\n",
    "                    x += 1\n",
    "                    y -= 1\n",
    "\n",
    "        return matrix\n",
    "    \n",
    "    # Helper functions for huffman encoding and RLE\n",
    "    def _build_huffman_tree(self, frequencies):\n",
    "        # Create a priority queue (min-heap) to build the Huffman tree\n",
    "        heap = [[weight, [symbol, \"\"]] for symbol, weight in frequencies.items()]\n",
    "        heapq.heapify(heap)\n",
    "        \n",
    "        while len(heap) > 1:\n",
    "            low = heapq.heappop(heap)\n",
    "            high = heapq.heappop(heap)\n",
    "            for pair in low[1:]:\n",
    "                pair[1] = '0' + pair[1]\n",
    "            for pair in high[1:]:\n",
    "                pair[1] = '1' + pair[1]\n",
    "            heapq.heappush(heap, [low[0] + high[0]] + low[1:] + high[1:])\n",
    "        \n",
    "        # Generate the Huffman codes\n",
    "        huffman_codes = {}\n",
    "        for symbol, code in heap[0][1:]:\n",
    "            huffman_codes[symbol] = code\n",
    "        return huffman_codes\n",
    "\n",
    "    def _run_length_encoding(self, matrix):\n",
    "        rle = []\n",
    "        zero_count = 0\n",
    "        \n",
    "        for value in matrix:\n",
    "            if value == 0:\n",
    "                zero_count += 1  # Increment zero counter\n",
    "                if zero_count == 16:\n",
    "                    rle.append((15, 0))\n",
    "                    zero_count = 0\n",
    "            else:\n",
    "                rle.append((zero_count, value))  # Store the number of zeros before the value\n",
    "                zero_count = 0  # Reset zero counter after encountering a non-zero value\n",
    "        \n",
    "        return rle\n",
    "\n",
    "    def _huffman_encoding(self, values):\n",
    "        frequencies = defaultdict(int)\n",
    "        for val in values:\n",
    "            frequencies[val] += 1\n",
    "        \n",
    "        huffman_codes = self._build_huffman_tree(frequencies)\n",
    "        return huffman_codes\n",
    "\n",
    "    # Function to encode the image post scaling dct and quantization into rle and huffman and store into a bin file\n",
    "    def _encode(self, flattened_matrices, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            rle_result = []\n",
    "\n",
    "            for i in range(0,len(flattened_matrices)):\n",
    "                rle = self._run_length_encoding(flattened_matrices[i])\n",
    "                rle_result.extend(rle)\n",
    "                rle_result.append((0,0))\n",
    "\n",
    "            values = [value for count, value in rle_result]  # Only values for Huffman encoding\n",
    "            huffman_codes = self._huffman_encoding(values)    \n",
    "\n",
    "            # Store the Quality Factor in the file \n",
    "            f.write(np.array([self.Q], dtype=np.uint8).tobytes()) \n",
    "            f.flush()\n",
    "        \n",
    "\n",
    "            # Store the Huffman table in the file (value -> huffman code mapping)\n",
    "            f.write(np.array([len(huffman_codes)], dtype=np.uint16).tobytes())  # Write the number of unique values in Huffman table\n",
    "            f.flush()            \n",
    " \n",
    "\n",
    "            # Collect all Huffman codes\n",
    "            all_huffman_codes = []\n",
    "\n",
    "            for value, code in huffman_codes.items():\n",
    "                f.write(np.array([value], dtype=np.int16).tobytes())  \n",
    "                f.flush()\n",
    "                size_in_bits = len(code)\n",
    "                f.write(np.array([size_in_bits], dtype=np.uint8).tobytes())  # Write the size of the Huffman code\n",
    "                f.flush()\n",
    "                all_huffman_codes.append(code)\n",
    "\n",
    "            all_huffman_codes_str = ''.join(all_huffman_codes)\n",
    "            total_size_in_bits = len(all_huffman_codes_str)\n",
    "\n",
    "            f.write(np.array([total_size_in_bits], dtype=np.uint32).tobytes())\n",
    "            f.flush()\n",
    "\n",
    "            padding_length = 0\n",
    "            if len(all_huffman_codes_str) % 8 != 0:\n",
    "                padding_length = 8 - (len(all_huffman_codes_str) % 8)\n",
    "            all_huffman_codes_str = all_huffman_codes_str + '0' * padding_length\n",
    "\n",
    "            bitstream = bitstring.BitStream(bin=all_huffman_codes_str)\n",
    "            f.write(bitstream.bytes)  # Write the Huffman code as bytes\n",
    "            f.flush()\n",
    "\n",
    "            # To store the RLE Result\n",
    "            # Store the size of the rle_result\n",
    "            f.write(np.array([len(rle_result)], dtype=np.uint32).tobytes())  \n",
    "            f.flush()            \n",
    "\n",
    "            all_huffman_codes = []\n",
    "            all_huffman_codes_str = ''\n",
    "\n",
    "            for count, value in rle_result:\n",
    "                huffman_code = huffman_codes[value]  # Find Huffman code for this value\n",
    "                size_in_bits = len(huffman_code)  # The size in bits of the Huffman code\n",
    "\n",
    "                f.write(np.array([count], dtype=np.uint8).tobytes())\n",
    "                f.write(np.array([size_in_bits], dtype=np.uint8).tobytes())\n",
    "\n",
    "                f.flush()\n",
    "\n",
    "                all_huffman_codes.append(huffman_code)\n",
    "\n",
    "            all_huffman_codes_str = ''.join(all_huffman_codes)\n",
    "            total_size_in_bits = len(all_huffman_codes_str)\n",
    "\n",
    "            # Calculate padding to ensure byte alignment\n",
    "            if total_size_in_bits % 8 != 0:\n",
    "                padding_length = 8 - (total_size_in_bits % 8)\n",
    "                all_huffman_codes_str += '0' * padding_length  # Add padding to the bitstream\n",
    "            else:\n",
    "                padding_length = 0\n",
    "\n",
    "            # Write the total size in bits to the file (before padding)\n",
    "            f.write(np.array([total_size_in_bits], dtype=np.uint32).tobytes())\n",
    "            f.flush()\n",
    "\n",
    "            # Convert the padded bitstream into a byte array\n",
    "            bitstream = bitstring.BitStream(bin=all_huffman_codes_str)\n",
    "            f.write(bitstream.bytes)  # Write the Huffman codes as bytes\n",
    "            f.flush()\n",
    "\n",
    "\n",
    "\n",
    "    # Finds the original value given the huffman code and the huffman table\n",
    "    def _decode_huffman_code(self, code_bits, huffman_codes):\n",
    "        # Reverse the Huffman coding to find the value for the given code bits\n",
    "        for value, huffman_code in huffman_codes.items():\n",
    "            if code_bits == huffman_code:\n",
    "                return value\n",
    "        raise ValueError(f\"Unknown Huffman code: {code_bits}\")\n",
    "\n",
    "    # takes as input the original image and a quality factor Q\n",
    "    def compress(self, image, filename):\n",
    "        image = image.astype('float32') # cast to float\n",
    "        image = image - 128.0 # rescale the values\n",
    "        chunks = self._chunkify(image) # break into 8x8 chunks \n",
    "        \n",
    "        flattened_matrices = []\n",
    "        for chunk in chunks:\n",
    "            quantized_matrix = self._quantize(self._dct2(chunk))\n",
    "            flattened_matrix = self._zigzag(quantized_matrix)\n",
    "            flattened_matrices.append(flattened_matrix)\n",
    "\n",
    "        self._encode(flattened_matrices, filename)\n",
    "\n",
    "    def decompress(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            # Read the Quality Factor (Q)\n",
    "            Q = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "            \n",
    "            # Read the Huffman table (number of entries)\n",
    "            num_huffman_codes = np.fromfile(f, dtype=np.uint16, count=1)[0]\n",
    "\n",
    "            huffman_codes = {}\n",
    "            \n",
    "            table_entries = []\n",
    "            # Read each Huffman code (value, size)\n",
    "            for _ in range(num_huffman_codes):\n",
    "                value = np.fromfile(f, dtype=np.int16, count=1)[0]\n",
    "                size_in_bits = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                table_entries.append((value,size_in_bits))\n",
    "            \n",
    "            length_huffman_codes = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "            huffman_codes_bitstream = f.read((length_huffman_codes + 7) // 8)  # Read the total size in bytes\n",
    "            huffman_codes_bitstream = bitstring.BitStream(bytes=huffman_codes_bitstream).bin\n",
    "\n",
    "            current_pos = 0\n",
    "            for value, size_in_bits in table_entries:\n",
    "                huffman_codes[value] = huffman_codes_bitstream[current_pos:current_pos+size_in_bits]\n",
    "                current_pos+=size_in_bits\n",
    "            \n",
    "\n",
    "            # get the number of rle values\n",
    "            num_rle_values = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "\n",
    "            # 3. Decode the RLE-encoded values and sizes\n",
    "            rle_result = []\n",
    "            table_entries = []\n",
    "\n",
    "            for _ in range(num_rle_values):\n",
    "                count = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                size_in_bits = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                table_entries.append((count, size_in_bits))\n",
    "            \n",
    "            # print(table_entries)\n",
    "            \n",
    "            length_huffman_codes = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "            huffman_codes_bitstream = f.read((length_huffman_codes + 7) // 8)  # Read the total size in bytes\n",
    "            huffman_codes_bitstream = bitstring.BitStream(bytes=huffman_codes_bitstream).bin\n",
    "\n",
    "            current_pos = 0\n",
    "            for count, size_in_bits in table_entries:\n",
    "                value = self._decode_huffman_code(huffman_codes_bitstream[current_pos:current_pos+size_in_bits], huffman_codes)\n",
    "                rle_result.append((count, value))\n",
    "                current_pos+=size_in_bits\n",
    "\n",
    "\n",
    "            # Reconstruct the original flattened matrices from RLE\n",
    "            flattened_matrices = []\n",
    "            \n",
    "            current_patch = []\n",
    "            for count, value in rle_result:\n",
    "                if count == 0 and value == 0:\n",
    "                    current_patch = current_patch + [0]*(64 - len(current_patch))\n",
    "                    flattened_matrices.append(np.array(current_patch))\n",
    "                    current_patch = []\n",
    "                else:\n",
    "                    current_patch = current_patch + [0]*count + [value]\n",
    "\n",
    "\n",
    "            # convert it back to the original patch dimensions\n",
    "            for i in range(len(flattened_matrices)):\n",
    "                \n",
    "                flattened_matrices[i] = self._reverse_zigzag(flattened_matrices[i], 8, 8)\n",
    "\n",
    "                # now de-quantize the matrix and rescale\n",
    "                flattened_matrices[i] = (flattened_matrices[i] * self.scaled_quantization_matrix) \n",
    "                flattened_matrices[i] = self._idct2(flattened_matrices[i]) + 128\n",
    "            \n",
    "            # combine the patches together\n",
    "            restored_image = self._dechunkify(flattened_matrices, (8*int(np.sqrt(len(flattened_matrices))), 8*int(np.sqrt(len(flattened_matrices)))))\n",
    "            return restored_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from PIL import Image\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# Assuming JPEG_Exp is the class you have implemented\n",
    "# Define quantization matrices\n",
    "JPEG_STANDARD = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
    "                          [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                          [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                          [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                          [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                          [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                          [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                          [72, 92, 95, 98, 112, 100, 103, 99]])\n",
    "\n",
    "HIGHLY_DETAILED = np.array([[4, 3, 3, 4, 6, 10, 13, 15],\n",
    "                            [3, 3, 4, 5, 7, 16, 16, 14],\n",
    "                            [4, 4, 5, 7, 10, 15, 18, 15],\n",
    "                            [4, 5, 6, 8, 14, 24, 23, 19],\n",
    "                            [6, 7, 11, 17, 20, 32, 30, 23],\n",
    "                            [10, 16, 25, 29, 37, 48, 53, 41],\n",
    "                            [13, 16, 20, 23, 28, 56, 55, 46],\n",
    "                            [15, 14, 15, 19, 23, 41, 43, 41]])\n",
    "\n",
    "LOW_DETAIL = np.array([[50, 40, 35, 50, 60, 80, 90, 100],\n",
    "                       [40, 40, 50, 60, 70, 100, 110, 90],\n",
    "                       [45, 50, 60, 75, 85, 100, 120, 100],\n",
    "                       [50, 60, 70, 90, 110, 150, 140, 120],\n",
    "                       [60, 70, 90, 110, 130, 180, 170, 140],\n",
    "                       [80, 100, 130, 140, 160, 200, 210, 160],\n",
    "                       [90, 110, 130, 150, 170, 220, 240, 190],\n",
    "                       [100, 120, 140, 160, 180, 220, 240, 210]])\n",
    "\n",
    "JPEG2000_LIKE = np.array([[9, 5, 4, 6, 8, 12, 16, 18],\n",
    "                          [5, 5, 6, 8, 10, 18, 19, 16],\n",
    "                          [6, 6, 8, 10, 14, 21, 24, 20],\n",
    "                          [6, 8, 10, 13, 17, 27, 26, 21],\n",
    "                          [8, 10, 14, 17, 21, 31, 29, 23],\n",
    "                          [12, 18, 21, 24, 30, 39, 42, 32],\n",
    "                          [16, 19, 24, 26, 33, 43, 44, 36],\n",
    "                          [18, 16, 20, 21, 26, 36, 39, 35]])\n",
    "\n",
    "UNIFORM = np.ones((8, 8)) * 20\n",
    "\n",
    "# Set up experiment parameters\n",
    "quality_factors = [10, 20, 30, 50, 75]\n",
    "quantization_matrices = {\n",
    "    \"JPEG Standard\": JPEG_STANDARD,\n",
    "    \"Highly Detailed\": HIGHLY_DETAILED,\n",
    "    \"Low Detail\": LOW_DETAIL,\n",
    "    \"JPEG2000-like\": JPEG2000_LIKE,\n",
    "    \"Uniform\": UNIFORM\n",
    "}\n",
    "\n",
    "# Create folder to store results\n",
    "output_folder = \"compression_results\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Function to calculate compression rate (CR)\n",
    "def calculate_compression_rate(original_size, compressed_size):\n",
    "    return original_size / compressed_size\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(original_image, decompressed_image):\n",
    "    return np.sqrt(mean_squared_error(original_image.flatten(), decompressed_image.flatten()))\n",
    "\n",
    "# Loop through all BMP files in the folder\n",
    "input_folder = \"data\"\n",
    "bmp_files = [f for f in os.listdir(input_folder) if f.endswith(\".bmp\")]\n",
    "\n",
    "# Initialize lists to store metrics for plotting\n",
    "cr_results = {matrix_name: [] for matrix_name in quantization_matrices.keys()}\n",
    "rmse_results = {matrix_name: [] for matrix_name in quantization_matrices.keys()}\n",
    "bpp_results = {matrix_name: [] for matrix_name in quantization_matrices.keys()}\n",
    "\n",
    "# Run the experiment for each image\n",
    "for file in bmp_files:\n",
    "    # Load the image\n",
    "    image_path = os.path.join(input_folder, file)\n",
    "    img = np.array(Image.open(image_path).convert('L'))  # Convert to grayscale\n",
    "\n",
    "    for matrix_name, matrix in quantization_matrices.items():\n",
    "        for Q in quality_factors:\n",
    "            # Instantiate the JPEG_Exp class with the specific quantization matrix and quality factor\n",
    "            jpeg_exp = JPEG_Exp(Q=Q, quantization_matrix=matrix)\n",
    "            \n",
    "            # Compress the image\n",
    "            compressed_file = os.path.join(output_folder, f\"{file}_compressed_Q{Q}_{matrix_name}.bin\")\n",
    "            jpeg_exp.compress(img, compressed_file)\n",
    "\n",
    "            # Decompress the image\n",
    "            decompressed_img = jpeg_exp.decompress(compressed_file)\n",
    "\n",
    "            # Calculate RMSE\n",
    "            rmse = calculate_rmse(img, decompressed_img)\n",
    "\n",
    "            # Calculate compression rate\n",
    "            original_size = img.nbytes\n",
    "            compressed_size = os.path.getsize(compressed_file)\n",
    "            cr = calculate_compression_rate(original_size, compressed_size)\n",
    "\n",
    "            # Calculate BPP (Bits Per Pixel)\n",
    "            bpp = compressed_size * 8 / img.size  # in bits per pixel\n",
    "\n",
    "            # Store results\n",
    "            cr_results[matrix_name].append(cr)\n",
    "            rmse_results[matrix_name].append(rmse)\n",
    "            bpp_results[matrix_name].append(bpp)\n",
    "\n",
    "            # Save the Q=50 compressed image for each matrix\n",
    "            if Q == 50:\n",
    "                q50_image_folder = os.path.join(output_folder, f\"Q50_{matrix_name}\")\n",
    "                if not os.path.exists(q50_image_folder):\n",
    "                    os.makedirs(q50_image_folder)\n",
    "                q50_image_path = os.path.join(q50_image_folder, f\"{file}\")\n",
    "                Image.fromarray(decompressed_img.astype(np.uint8)).save(q50_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Assuming these are your concatenated results\n",
    "# cr_results = {\"matrix_name\": [concatenated data]}\n",
    "# rmse_results = {\"matrix_name\": [concatenated data]}\n",
    "# bpp_results = {\"matrix_name\": [concatenated data]}\n",
    "# Replace this with the actual dictionaries you have\n",
    "\n",
    "# Number of images\n",
    "num_images = len(bmp_files)\n",
    "\n",
    "# Number of quality factors\n",
    "num_quality_factors = len(quality_factors)\n",
    "\n",
    "# Restructure results\n",
    "image_results = {file: {\"cr_results\": {}, \"rmse_results\": {}, \"bpp_results\": {}} for file in bmp_files}\n",
    "\n",
    "for matrix_name in quantization_matrices.keys():\n",
    "    # Split the data for each metric\n",
    "    cr_data = np.array(cr_results[matrix_name])\n",
    "    rmse_data = np.array(rmse_results[matrix_name])\n",
    "    bpp_data = np.array(bpp_results[matrix_name])\n",
    "\n",
    "    # Reshape the data into [num_images, num_quality_factors]\n",
    "    cr_split = cr_data.reshape(num_images, num_quality_factors)\n",
    "    rmse_split = rmse_data.reshape(num_images, num_quality_factors)\n",
    "    bpp_split = bpp_data.reshape(num_images, num_quality_factors)\n",
    "\n",
    "    for idx, file in enumerate(bmp_files):\n",
    "        image_results[file][\"cr_results\"][matrix_name] = cr_split[idx, :]\n",
    "        image_results[file][\"rmse_results\"][matrix_name] = rmse_split[idx, :]\n",
    "        image_results[file][\"bpp_results\"][matrix_name] = bpp_split[idx, :]\n",
    "\n",
    "# Generate and save plots for each image\n",
    "output_folder = \"compression_results\"\n",
    "\n",
    "for file in bmp_files:\n",
    "    metrics = image_results[file]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Compression Rate vs Q Factor\n",
    "    for matrix_name in quantization_matrices.keys():\n",
    "        axes[0].plot(quality_factors, metrics[\"cr_results\"][matrix_name], label=matrix_name)\n",
    "    axes[0].set_title(f'Compression Rate vs Q Factor\\n{file}')\n",
    "    axes[0].set_xlabel('Q Factor')\n",
    "    axes[0].set_ylabel('Compression Rate')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # RMSE vs BPP\n",
    "    for matrix_name in quantization_matrices.keys():\n",
    "        axes[1].plot(metrics[\"bpp_results\"][matrix_name], metrics[\"rmse_results\"][matrix_name], label=matrix_name)\n",
    "    axes[1].set_title(f'RMSE vs BPP\\n{file}')\n",
    "    axes[1].set_xlabel('BPP')\n",
    "    axes[1].set_ylabel('RMSE')\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Save the plots\n",
    "    plot_path = os.path.join(output_folder, f\"{os.path.splitext(file)[0]}_plots.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collage\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "input_folder = \"data\"  # Folder containing original images\n",
    "folders = [\"Q50_JPEG Standard\", \"Q50_Highly Detailed\", \"Q50_Low Detail\", \"Q50_JPEG2000-like\", \"Q50_Uniform\"]\n",
    "output_folder = \"collages\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get list of original images\n",
    "original_images = [f for f in os.listdir(input_folder) if f.endswith(\".bmp\")]\n",
    "\n",
    "# Create a collage for each image\n",
    "for original_image in original_images:\n",
    "    # Load the original image\n",
    "    original_path = os.path.join(input_folder, original_image)\n",
    "    original = Image.open(original_path)\n",
    "\n",
    "    # Load Q=50 images from each folder\n",
    "    q50_images = []\n",
    "    for folder in folders:\n",
    "        q50_path = os.path.join(\"compression_results\", folder, original_image)\n",
    "        if os.path.exists(q50_path):\n",
    "            q50_images.append(Image.open(q50_path))\n",
    "        else:\n",
    "            print(f\"Warning: File {q50_path} not found.\")\n",
    "            q50_images.append(None)\n",
    "\n",
    "    # Create a 4x2 collage\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle(f\"Collage for {original_image}\", fontsize=16)\n",
    "\n",
    "    # Place Original image in the first position\n",
    "    axes[0, 0].imshow(original, cmap=\"gray\")\n",
    "    axes[0, 0].set_title(\"Original\")\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    # Place Q=50 images\n",
    "    for idx, (ax, matrix_name, q50_img) in enumerate(zip(axes.flatten()[1:], folders, q50_images)):\n",
    "        if q50_img:\n",
    "            ax.imshow(q50_img, cmap=\"gray\")\n",
    "            ax.set_title(f\"{matrix_name} (Q=50)\")\n",
    "        else:\n",
    "            ax.set_title(f\"{matrix_name} (Missing)\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for ax in axes.flatten()[len(q50_images) + 1:]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "    # Save the collage\n",
    "    collage_path = os.path.join(output_folder, f\"{os.path.splitext(original_image)[0]}_collage.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(collage_path)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
