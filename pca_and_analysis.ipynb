{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, data):\n",
    "        # Center the data by subtracting the mean\n",
    "        num_images, num_pixels = data.shape\n",
    "        self.mean = np.mean(data, axis=0)\n",
    "        centered_data = data - self.mean\n",
    "\n",
    "        # Calculate the covariance matrix\n",
    "        cov_matrix = np.cov(centered_data, rowvar=False)\n",
    "\n",
    "        # Compute the eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "        # Sort eigenvalues and eigenvectors in descending order\n",
    "        sorted_indices = np.argsort(eigenvalues)[::-1]  # This line calculates the indices that would sort the eigenvalues in ascending order and then reverses the order\n",
    "        self.eigenvalues = eigenvalues[sorted_indices]\n",
    "        self.eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "        # Select the top n_components eigenvectors\n",
    "        self.components = self.eigenvectors[:, :self.n_components]\n",
    "\n",
    "    def compress(self, data, output_file=\"compression_output.npy\"):\n",
    "        # Center the data (subtract the mean)\n",
    "        centered_data = data - self.mean\n",
    "        \n",
    "        # Compress the data by projecting it onto the components\n",
    "        compressed_data = np.dot(centered_data, self.components)\n",
    "        \n",
    "        compressed_data = compressed_data.astype(\"int16\")\n",
    "        self.components = self.components.astype(\"float16\")\n",
    "        self.mean = self.mean.astype(\"uint8\")\n",
    "\n",
    "        # Store the data into a binary file using np.save (for single array)\n",
    "        with open(output_file, 'wb') as f:\n",
    "            # Saving compressed data, components, and mean to the binary file\n",
    "            np.save(f, compressed_data)  # Saving compressed data\n",
    "            np.save(f, self.components)  # Saving components (PCA basis)\n",
    "            np.save(f, self.mean)        # Saving the mean\n",
    "        \n",
    "        print(f\"Compression details saved to {output_file}.\")\n",
    "\n",
    "\n",
    "    def decompress(self, file_name=\"compression_output.npy\"):\n",
    "        # Open the file in read mode and load the data\n",
    "        with open(file_name, 'rb') as f:\n",
    "            compressed_data = np.load(f)  # Load the compressed data\n",
    "            components = np.load(f)       # Load the components\n",
    "            mean = np.load(f)            # Load the mean\n",
    "\n",
    "\n",
    "        decompressed_data = np.dot(compressed_data, components.T) + mean\n",
    "        return decompressed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision with JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import dct, idct\n",
    "import bitstring\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "import heapq\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JPEG:\n",
    "    def __init__(self, Q = 50):\n",
    "        self.Q = Q\n",
    "        self.quantization_matrix = np.array([   [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "                                                [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                                                [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                                                [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                                                [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                                                [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                                                [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                                                [72, 92, 95, 98, 112, 100, 103, 99],])\n",
    "        self.scaled_quantization_matrix = np.round(self.quantization_matrix * (50.0/Q))\n",
    "    \n",
    "    # define the dct and idct functions for the blocks\n",
    "    def _dct2(self, block):\n",
    "        dct_val = dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
    "        return dct_val\n",
    "\n",
    "    def _idct2(self, block):\n",
    "        return idct(idct(block.T, norm='ortho').T, norm='ortho')\n",
    "    \n",
    "    # Runs quantization while compression\n",
    "    def _quantize(self, block):\n",
    "        return np.round(block / self.scaled_quantization_matrix)\n",
    "\n",
    "    # Runs dequantization while decompression\n",
    "    def _dequantize(self, block):\n",
    "        return block * self.scaled_quantization_matrix\n",
    "    \n",
    "    # breaks the image into 8x8 patches\n",
    "    def _chunkify(self, image):\n",
    "        chunks = []\n",
    "        h,w = np.shape(image)\n",
    "        for i in range(0, h, 8):\n",
    "            for j in range(0, w, 8):\n",
    "                chunk = image[i:i+8, j:j+8]\n",
    "                chunks.append(chunk)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    # recombines the patches into the original image size\n",
    "    def _dechunkify(self, chunks, original_shape):\n",
    "        h, w = original_shape\n",
    "        image = np.zeros((h, w), dtype=chunks[0].dtype)  # Create an empty array with the original shape\n",
    "        chunk_idx = 0  # Index to keep track of the current chunk\n",
    "\n",
    "        for i in range(0, h, 8):\n",
    "            for j in range(0, w, 8):\n",
    "                # Place the current chunk into the corresponding position in the image\n",
    "                image[i:i+8, j:j+8] = chunks[chunk_idx]\n",
    "                chunk_idx += 1\n",
    "\n",
    "        return image\n",
    "\n",
    "    # flattens the matrix into its zig-zag traversal\n",
    "    def _zigzag(self, matrix):\n",
    "        rows, cols = matrix.shape\n",
    "        result = []\n",
    "\n",
    "        for s in range(rows + cols - 1):\n",
    "            if s % 2 == 0:  # Even diagonals (move up-right)\n",
    "                x = min(s, rows - 1)\n",
    "                y = s - x\n",
    "                while x >= 0 and y < cols:\n",
    "                    result.append(matrix[x, y])\n",
    "                    x -= 1\n",
    "                    y += 1\n",
    "            else:  # Odd diagonals (move down-left)\n",
    "                y = min(s, cols - 1)\n",
    "                x = s - y\n",
    "                while y >= 0 and x < rows:\n",
    "                    result.append(matrix[x, y])\n",
    "                    x += 1\n",
    "                    y -= 1\n",
    "\n",
    "        return np.array(result)\n",
    "\n",
    "    # converts a flattened matrix into the original form by placing the elements in a zig zag manner\n",
    "    def _reverse_zigzag(self, flattened, rows, cols):\n",
    "        # Initialize an empty 2D matrix\n",
    "        matrix = np.zeros((rows, cols), dtype=flattened.dtype)\n",
    "\n",
    "        # Fill the matrix using the reverse zig-zag order\n",
    "        index = 0\n",
    "        for s in range(rows + cols - 1):\n",
    "            if s % 2 == 0:  # Even diagonals (move up-right)\n",
    "                x = min(s, rows - 1)\n",
    "                y = s - x\n",
    "                while x >= 0 and y < cols:\n",
    "                    matrix[x, y] = flattened[index]\n",
    "                    index += 1\n",
    "                    x -= 1\n",
    "                    y += 1\n",
    "            else:  # Odd diagonals (move down-left)\n",
    "                y = min(s, cols - 1)\n",
    "                x = s - y\n",
    "                while y >= 0 and x < rows:\n",
    "                    matrix[x, y] = flattened[index]\n",
    "                    index += 1\n",
    "                    x += 1\n",
    "                    y -= 1\n",
    "\n",
    "        return matrix\n",
    "    \n",
    "    # Helper functions for huffman encoding and RLE\n",
    "    def _build_huffman_tree(self, frequencies):\n",
    "        # Create a priority queue (min-heap) to build the Huffman tree\n",
    "        heap = [[weight, [symbol, \"\"]] for symbol, weight in frequencies.items()]\n",
    "        heapq.heapify(heap)\n",
    "        \n",
    "        while len(heap) > 1:\n",
    "            low = heapq.heappop(heap)\n",
    "            high = heapq.heappop(heap)\n",
    "            for pair in low[1:]:\n",
    "                pair[1] = '0' + pair[1]\n",
    "            for pair in high[1:]:\n",
    "                pair[1] = '1' + pair[1]\n",
    "            heapq.heappush(heap, [low[0] + high[0]] + low[1:] + high[1:])\n",
    "        \n",
    "        # Generate the Huffman codes\n",
    "        huffman_codes = {}\n",
    "        for symbol, code in heap[0][1:]:\n",
    "            huffman_codes[symbol] = code\n",
    "        return huffman_codes\n",
    "\n",
    "    def _run_length_encoding(self, matrix):\n",
    "        rle = []\n",
    "        zero_count = 0\n",
    "        \n",
    "        for value in matrix:\n",
    "            if value == 0:\n",
    "                zero_count += 1  # Increment zero counter\n",
    "                if zero_count == 16:\n",
    "                    rle.append((15, 0))\n",
    "                    zero_count = 0\n",
    "            else:\n",
    "                rle.append((zero_count, value))  # Store the number of zeros before the value\n",
    "                zero_count = 0  # Reset zero counter after encountering a non-zero value\n",
    "        \n",
    "        return rle\n",
    "\n",
    "    def _huffman_encoding(self, values):\n",
    "        frequencies = defaultdict(int)\n",
    "        for val in values:\n",
    "            frequencies[val] += 1\n",
    "        \n",
    "        huffman_codes = self._build_huffman_tree(frequencies)\n",
    "        return huffman_codes\n",
    "\n",
    "    # Function to encode the image post scaling dct and quantization into rle and huffman and store into a bin file\n",
    "    def _encode(self, flattened_matrices, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            rle_result = []\n",
    "\n",
    "            for i in range(0,len(flattened_matrices)):\n",
    "                rle = self._run_length_encoding(flattened_matrices[i])\n",
    "                rle_result.extend(rle)\n",
    "                rle_result.append((0,0))\n",
    "\n",
    "            values = [value for count, value in rle_result]  # Only values for Huffman encoding\n",
    "            huffman_codes = self._huffman_encoding(values)    \n",
    "\n",
    "            # Store the Quality Factor in the file \n",
    "            f.write(np.array([self.Q], dtype=np.uint8).tobytes()) \n",
    "            f.flush()\n",
    "        \n",
    "\n",
    "            # Store the Huffman table in the file (value -> huffman code mapping)\n",
    "            f.write(np.array([len(huffman_codes)], dtype=np.uint16).tobytes())  # Write the number of unique values in Huffman table\n",
    "            f.flush()            \n",
    " \n",
    "\n",
    "            # Collect all Huffman codes\n",
    "            all_huffman_codes = []\n",
    "\n",
    "            for value, code in huffman_codes.items():\n",
    "                f.write(np.array([value], dtype=np.int16).tobytes())  \n",
    "                f.flush()\n",
    "                size_in_bits = len(code)\n",
    "                f.write(np.array([size_in_bits], dtype=np.uint8).tobytes())  # Write the size of the Huffman code\n",
    "                f.flush()\n",
    "                all_huffman_codes.append(code)\n",
    "\n",
    "            all_huffman_codes_str = ''.join(all_huffman_codes)\n",
    "            total_size_in_bits = len(all_huffman_codes_str)\n",
    "\n",
    "            f.write(np.array([total_size_in_bits], dtype=np.uint32).tobytes())\n",
    "            f.flush()\n",
    "\n",
    "            padding_length = 0\n",
    "            if len(all_huffman_codes_str) % 8 != 0:\n",
    "                padding_length = 8 - (len(all_huffman_codes_str) % 8)\n",
    "            all_huffman_codes_str = all_huffman_codes_str + '0' * padding_length\n",
    "\n",
    "            bitstream = bitstring.BitStream(bin=all_huffman_codes_str)\n",
    "            f.write(bitstream.bytes)  # Write the Huffman code as bytes\n",
    "            f.flush()\n",
    "\n",
    "            # To store the RLE Result\n",
    "            # Store the size of the rle_result\n",
    "            f.write(np.array([len(rle_result)], dtype=np.uint32).tobytes())  \n",
    "            f.flush()            \n",
    "\n",
    "            all_huffman_codes = []\n",
    "            all_huffman_codes_str = ''\n",
    "\n",
    "            for count, value in rle_result:\n",
    "                huffman_code = huffman_codes[value]  # Find Huffman code for this value\n",
    "                size_in_bits = len(huffman_code)  # The size in bits of the Huffman code\n",
    "\n",
    "                f.write(np.array([count], dtype=np.uint8).tobytes())\n",
    "                f.write(np.array([size_in_bits], dtype=np.uint8).tobytes())\n",
    "\n",
    "                f.flush()\n",
    "\n",
    "                all_huffman_codes.append(huffman_code)\n",
    "\n",
    "            all_huffman_codes_str = ''.join(all_huffman_codes)\n",
    "            total_size_in_bits = len(all_huffman_codes_str)\n",
    "\n",
    "            # Calculate padding to ensure byte alignment\n",
    "            if total_size_in_bits % 8 != 0:\n",
    "                padding_length = 8 - (total_size_in_bits % 8)\n",
    "                all_huffman_codes_str += '0' * padding_length  # Add padding to the bitstream\n",
    "            else:\n",
    "                padding_length = 0\n",
    "\n",
    "            # Write the total size in bits to the file (before padding)\n",
    "            f.write(np.array([total_size_in_bits], dtype=np.uint32).tobytes())\n",
    "            f.flush()\n",
    "\n",
    "            # Convert the padded bitstream into a byte array\n",
    "            bitstream = bitstring.BitStream(bin=all_huffman_codes_str)\n",
    "            f.write(bitstream.bytes)  # Write the Huffman codes as bytes\n",
    "            f.flush()\n",
    "\n",
    "\n",
    "\n",
    "    # Finds the original value given the huffman code and the huffman table\n",
    "    def _decode_huffman_code(self, code_bits, huffman_codes):\n",
    "        # Reverse the Huffman coding to find the value for the given code bits\n",
    "        for value, huffman_code in huffman_codes.items():\n",
    "            if code_bits == huffman_code:\n",
    "                return value\n",
    "        raise ValueError(f\"Unknown Huffman code: {code_bits}\")\n",
    "\n",
    "    # takes as input the original image and a quality factor Q\n",
    "    def compress(self, image, filename):\n",
    "        image = image.astype('float32') # cast to float\n",
    "        image = image - 128.0 # rescale the values\n",
    "        chunks = self._chunkify(image) # break into 8x8 chunks \n",
    "        \n",
    "        flattened_matrices = []\n",
    "        for chunk in chunks:\n",
    "            quantized_matrix = self._quantize(self._dct2(chunk))\n",
    "            flattened_matrix = self._zigzag(quantized_matrix)\n",
    "            flattened_matrices.append(flattened_matrix)\n",
    "\n",
    "        self._encode(flattened_matrices, filename)\n",
    "\n",
    "    def decompress(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            # Read the Quality Factor (Q)\n",
    "            Q = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "            \n",
    "            # Read the Huffman table (number of entries)\n",
    "            num_huffman_codes = np.fromfile(f, dtype=np.uint16, count=1)[0]\n",
    "\n",
    "            huffman_codes = {}\n",
    "            \n",
    "            table_entries = []\n",
    "            # Read each Huffman code (value, size)\n",
    "            for _ in range(num_huffman_codes):\n",
    "                value = np.fromfile(f, dtype=np.int16, count=1)[0]\n",
    "                size_in_bits = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                table_entries.append((value,size_in_bits))\n",
    "            \n",
    "            length_huffman_codes = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "            huffman_codes_bitstream = f.read((length_huffman_codes + 7) // 8)  # Read the total size in bytes\n",
    "            huffman_codes_bitstream = bitstring.BitStream(bytes=huffman_codes_bitstream).bin\n",
    "\n",
    "            current_pos = 0\n",
    "            for value, size_in_bits in table_entries:\n",
    "                huffman_codes[value] = huffman_codes_bitstream[current_pos:current_pos+size_in_bits]\n",
    "                current_pos+=size_in_bits\n",
    "            \n",
    "\n",
    "            # get the number of rle values\n",
    "            num_rle_values = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "\n",
    "            # 3. Decode the RLE-encoded values and sizes\n",
    "            rle_result = []\n",
    "            table_entries = []\n",
    "\n",
    "            for _ in range(num_rle_values):\n",
    "                count = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                size_in_bits = np.fromfile(f, dtype=np.uint8, count=1)[0]\n",
    "                table_entries.append((count, size_in_bits))\n",
    "            \n",
    "            # print(table_entries)\n",
    "            \n",
    "            length_huffman_codes = np.fromfile(f, dtype=np.uint32, count=1)[0]\n",
    "            huffman_codes_bitstream = f.read((length_huffman_codes + 7) // 8)  # Read the total size in bytes\n",
    "            huffman_codes_bitstream = bitstring.BitStream(bytes=huffman_codes_bitstream).bin\n",
    "\n",
    "            current_pos = 0\n",
    "            for count, size_in_bits in table_entries:\n",
    "                value = self._decode_huffman_code(huffman_codes_bitstream[current_pos:current_pos+size_in_bits], huffman_codes)\n",
    "                rle_result.append((count, value))\n",
    "                current_pos+=size_in_bits\n",
    "\n",
    "\n",
    "            # Reconstruct the original flattened matrices from RLE\n",
    "            flattened_matrices = []\n",
    "            \n",
    "            current_patch = []\n",
    "            for count, value in rle_result:\n",
    "                if count == 0 and value == 0:\n",
    "                    current_patch = current_patch + [0]*(64 - len(current_patch))\n",
    "                    flattened_matrices.append(np.array(current_patch))\n",
    "                    current_patch = []\n",
    "                else:\n",
    "                    current_patch = current_patch + [0]*count + [value]\n",
    "\n",
    "\n",
    "            # convert it back to the original patch dimensions\n",
    "            for i in range(len(flattened_matrices)):\n",
    "                \n",
    "                flattened_matrices[i] = self._reverse_zigzag(flattened_matrices[i], 8, 8)\n",
    "\n",
    "                # now de-quantize the matrix and rescale\n",
    "                flattened_matrices[i] = (flattened_matrices[i] * self.scaled_quantization_matrix) \n",
    "                flattened_matrices[i] = self._idct2(flattened_matrices[i]) + 128\n",
    "            \n",
    "            # combine the patches together\n",
    "            restored_image = self._dechunkify(flattened_matrices, (8*int(np.sqrt(len(flattened_matrices))), 8*int(np.sqrt(len(flattened_matrices)))))\n",
    "            return restored_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(original_image, decompressed_image):\n",
    "    # Flatten the images to 1D arrays for easier comparison\n",
    "    original_image = original_image.astype(np.float64)\n",
    "    decompressed_image = decompressed_image.astype(np.float64)\n",
    "\n",
    "    # Compute the squared differences\n",
    "    squared_diff = (original_image - decompressed_image) ** 2\n",
    "\n",
    "    # Calculate the mean squared error (MSE)\n",
    "    mse = np.mean(squared_diff)\n",
    "\n",
    "    # RMSE is the square root of MSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "def get_image_size_in_bits(image_path):\n",
    "    # Get image size in bytes\n",
    "    size_in_bytes = os.path.getsize(image_path)\n",
    "    # Convert bytes to bits\n",
    "    return size_in_bytes * 8\n",
    "\n",
    "def calculate_compression_rate(original_path, compressed_data_path):\n",
    "    \"\"\"Calculate compression rate as size of compressed data vs original size.\"\"\"\n",
    "    return get_image_size_in_bits(original_path) / get_image_size_in_bits(compressed_data_path)\n",
    "\n",
    "def calculate_bpp(compressed_image_path, image_shape):\n",
    "    # Get the compressed file size in bits (1 byte = 8 bits)\n",
    "    file_size_in_bits = os.path.getsize(compressed_image_path) * 8\n",
    "\n",
    "    # Calculate the total number of pixels in the image\n",
    "    num_pixels = image_shape[0] * image_shape[1]\n",
    "\n",
    "    # Compute BPP\n",
    "    bpp = file_size_in_bits / num_pixels\n",
    "\n",
    "    return bpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "quality_factors = range(10, 101, 10)  # Quality factors from 10 to 100 in steps of 5\n",
    "images_directory = \"data/\"  # Directory with at least 20 images\n",
    "output_directory = \"compressed_images_bin/\"  # Directory to save compressed images\n",
    "graphs_directory = \"pca_comparison/\"\n",
    "compressed_images_directory = \"compressed_images/\"\n",
    "\n",
    "# Process images\n",
    "image_files = [os.path.join(images_directory, f) for f in os.listdir(images_directory)]\n",
    "\n",
    "# Loop through each image and process\n",
    "i=0\n",
    "for image_path in image_files:\n",
    "    print(i)\n",
    "    i+=1\n",
    "    rmse_values_pca = []\n",
    "    bpp_values_pca = []\n",
    "    rmse_values_custom = []\n",
    "    bpp_values_custom = []\n",
    "    compression_rate_pca = []\n",
    "    compression_rate_custom = []\n",
    "    \n",
    "    original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    for q in quality_factors:\n",
    "        \n",
    "        # Custom JPEG Compression (assuming custom JPEG class is defined)\n",
    "        jpeg = JPEG(Q=q)  # Assuming your custom JPEG implementation is called 'JPEG'\n",
    "        \n",
    "        compressed_path_custom = os.path.join(output_directory, f\"custom_compressed_q{q}_{os.path.splitext(os.path.basename(image_path))[0]}\")\n",
    "        jpeg.compress(original_image, compressed_path_custom)  \n",
    "        decompressed_image_custom = jpeg.decompress(compressed_path_custom)  # Decompress using custom method\n",
    "\n",
    "        decompressed_image_path_custom = os.path.join(compressed_images_directory, f\"custom_compressed_q{q}_{os.path.splitext(os.path.basename(image_path))[0]}.jpg\")\n",
    "\n",
    "        # Save the decompressed custom image as a .jpg file\n",
    "        cv2.imwrite(decompressed_image_path_custom, decompressed_image_custom)\n",
    "\n",
    "        # Check for shape mismatch\n",
    "        if original_image.shape != decompressed_image_custom.shape:\n",
    "            print(f\"Error in image_path: {image_path}, Quality Factor: {q}\")\n",
    "            continue\n",
    "\n",
    "        # Calculate RMSE and BPP for custom method\n",
    "        rmse_custom = calculate_rmse(original_image, decompressed_image_custom)\n",
    "        bpp_custom = calculate_bpp(compressed_path_custom, original_image.shape)\n",
    "\n",
    "        # Calculate Compression Rate for custom method\n",
    "        original_size_custom = os.path.getsize(image_path)\n",
    "        compressed_size_custom = os.path.getsize(compressed_path_custom)\n",
    "        compression_rate_custom.append(original_size_custom / compressed_size_custom)\n",
    "    \n",
    "        rmse_values_custom.append(rmse_custom)\n",
    "        bpp_values_custom.append(bpp_custom)\n",
    "\n",
    "    for k in range(1, 251, 25):\n",
    "            # PCA Compression and Decompression\n",
    "            pca_1 = PCA(k)\n",
    "            pca_1.fit(original_image)\n",
    "            pca_1.compress(original_image)\n",
    "            decompressed_image_pca = pca_1.decompress(\"compression_output.npy\")\n",
    "            rmse_values_pca.append(calculate_rmse(original_image, decompressed_image_pca))\n",
    "            compression_rate_pca.append(calculate_compression_rate(image_path, \"compression_output.npy\"))\n",
    "            bpp_values_pca.append(calculate_bpp(\"compression_output.npy\", original_image.shape))\n",
    "\n",
    "\n",
    "    # Plot the comparison of RMSE vs BPP for both methods (OpenCV vs Custom JPEG)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(bpp_values_pca, rmse_values_pca, marker='o', linestyle='-', label='PCA', color='blue')\n",
    "    plt.plot(bpp_values_custom, rmse_values_custom, marker='o', linestyle='-', label='Custom JPEG', color='red')\n",
    "    plt.xlabel('Bits Per Pixel (BPP)')\n",
    "    plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "    plt.title(f'RMSE vs BPP for Image {os.path.splitext(os.path.basename(image_path))[0]}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the comparison plot\n",
    "    plot_filename = os.path.join(graphs_directory, f\"rmse_vs_bpp_comparison_{os.path.splitext(os.path.basename(image_path))[0]}.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()  # Close the figure to avoid overlapping plots\n",
    "\n",
    "    # Plot Compression Rate vs k for PCA\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, 501, 50), compression_rate_pca, marker='o', linestyle='-', label='PCA', color='blue')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Compression Rate')\n",
    "    plt.title(f'Compression Rate vs k for Image {os.path.splitext(os.path.basename(image_path))[0]}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the compression rate plot\n",
    "    rate_plot_filename = os.path.join(graphs_directory, f\"compression_rate_vs_k_{os.path.splitext(os.path.basename(image_path))[0]}.png\")\n",
    "    plt.savefig(rate_plot_filename)\n",
    "    plt.close()  # Close the figure to avoid overlapping plots\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
